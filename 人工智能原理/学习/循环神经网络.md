# 循环神经网络

# 一、RNN、LSTM、GRU

## 1.1 RNN

![RNN](pngs/RNN.png)

> **公式**：$H_t = \tanh (X_t W_{xh} + H_{t-1} W_{hh} + b_h)$

## 1.2 LSTM

![LSTM](pngs/LSTM.png)

> 1. **遗忘门**: $F_t = \sigma (X_t W_{xf} + H_{t-1} W_{hf} + b_f)$
> 2. **输入门**: $I_t = \sigma (X_t W_{xi} + H_{t-1} W_{hi} + b_i)$
> 3. **候选记忆细胞**: $\tilde{C}_t = \tanh (X_t W_{xc} + H_{t-1} W_{hc} + b_c)$
> 4. **记忆细胞**: $C_t = F_t \odot C_{t-1} + I_t \odot \tilde{C}_t$
> 5. **输出门**: $O_t = \sigma (X_t W_{xo} + H_{t-1} W_{ho} + b_o)$
> 6. **隐藏状态**: $H_t = O_t \odot \tanh (C_t)$

## 1.3 GRU

![GRU](pngs/GRU.png)

> 1. **重置门**: $R_t = \sigma (X_t W_{xr} + H_{t-1} W_{hr} + b_r)$
> 2. **候选隐藏状态**: $\tilde{H}_t = \tanh (X_t W_{xh} + (R_t \odot H_{t-1}) W_{hh} + b_h)$
>    - **重置门**帮助捕捉短期依赖关系，控制有多少过去信息用于生成新的“候选记忆”
> 3. **更新门**: $Z_t = \sigma (X_t W_{xz} + H_{t-1} W_{hz} + b_z)$
> 4. **隐藏状态**: $H_t = Z_t \odot H_{t-1} + (1-Z_t) \odot \tilde{H}_t$
>    - 更新门帮助捕捉长期依赖关系，控制有多少过去记忆被直接传递到未来。

---

**todo**