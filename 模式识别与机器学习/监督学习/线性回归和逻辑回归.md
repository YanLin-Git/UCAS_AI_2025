# 线性回归和逻辑回归

> 这节不详细整理笔记了，随便写写


## 一、线性模型

```mermaid
graph LR
    G[广义线性模型]
    G -.回归问题.- X[线性回归] --- N[因变量y服从高斯分布]
    G -.二分类.- L[逻辑回归] --- B[因变量y服从伯努利分布]
    G -.多分类.- S[softmax] --- M[因变量y服从多类别分布] 
```

- 都可以用概率论的知识来推导
    1. 假设因变量y服从某个分布，写出似然函数
    2. 最大似然估计，得到优化目标
    3. 梯度下降法，求解

## 二、优化算法

1. **线性回归**可以用解析法，直接求最小值。
    - 回想一下二次函数 $y=ax^2+b$ 求最小值
    - 但是计算量很大
2. **逻辑回归**就没法直接求了。

于是老师介绍了**梯度下降算法**，以及它的一些变体。

> 自己画的一张图，不一定准确。仅供参考～
> ```mermaid
> graph LR
>     SGD[SGD] --- Momentum[Momentum] & AdaGrad[AdaGrad]
>     AdaGrad --- RMSProp[RMSProp] & AdaDelta[AdaDelta]
>     Momentum & RMSProp --- Adam[Adam]
>     Adam --- AdamW[AdamW]
> ```